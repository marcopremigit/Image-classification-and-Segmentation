{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8itnFnnx3ntq"
   },
   "source": [
    "# Initializations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tOBDSA9BnFIx"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "from numpy.random import shuffle\n",
    "import shutil\n",
    "import patchify as p\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import time\n",
    "from matplotlib import cm\n",
    "import segmentation_models as sm\n",
    "\n",
    "# Set the seed for random operations. \n",
    "# This let our experiments to be reproducible. \n",
    "SEED = 1234\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gpu in tf.config.experimental.list_physical_devices('GPU'):\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sh5NWR_0DceA"
   },
   "source": [
    "# Hyperparameter Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bCYwTG9lDcId"
   },
   "outputs": [],
   "source": [
    "img_w, img_h = 512, 512\n",
    "\n",
    "# Optimization params\n",
    "bs = 4\n",
    "lr = 1e-3\n",
    "decay = 0.1\n",
    "min_lr = 1e-6\n",
    "\n",
    "apply_data_augmentation = True\n",
    "\n",
    "mode = \"bipbip\"\n",
    "plant = \"haricot\"\n",
    "\n",
    "BACKBONE = \"custom\"\n",
    "\n",
    "loss_name = \"loss\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1YT1i2asB8iz"
   },
   "source": [
    "# Script Comprehension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YKYjoayM4Vhy"
   },
   "source": [
    "Converting in classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2QI3ABYWp4HR"
   },
   "outputs": [],
   "source": [
    "# Converts images to RGB to Target\n",
    "def read_rgb_mask(img_path):\n",
    "    '''\n",
    "    img_path: path to the mask file\n",
    "    Returns the numpy array containing target values\n",
    "    '''\n",
    "\n",
    "    mask_img = Image.open(img_path)\n",
    "    mask_arr = np.array(mask_img)\n",
    "\n",
    "    new_mask_arr = np.zeros(mask_arr.shape[:2], dtype=mask_arr.dtype)\n",
    "\n",
    "    # Use RGB dictionary in 'RGBtoTarget.txt' to convert RGB to target\n",
    "    new_mask_arr[np.where(np.all(mask_arr == [254, 124, 18], axis=-1))] = 0\n",
    "    new_mask_arr[np.where(np.all(mask_arr == [255, 255, 255], axis=-1))] = 1\n",
    "    new_mask_arr[np.where(np.all(mask_arr == [216, 67, 82], axis=-1))] = 2\n",
    "\n",
    "    return new_mask_arr\n",
    "\n",
    "def mask_to_rgb(mask_arr):\n",
    "\n",
    "    mask = np.squeeze(mask_arr, axis=2)\n",
    "    new_mask_arr = np.zeros((mask_arr.shape[0], mask_arr.shape[1], 3), dtype=mask_arr.dtype)\n",
    "\n",
    "    new_mask_arr[np.where(mask == 0)] = np.array([0, 0, 0])\n",
    "    new_mask_arr[np.where(mask == 1)] = np.array([255, 255, 255])\n",
    "    new_mask_arr[np.where(mask == 2)] = np.array([216, 67, 82])\n",
    "\n",
    "    return new_mask_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fTlvojWQHlfn"
   },
   "source": [
    "RLE Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j6vBas5xHk8Z"
   },
   "outputs": [],
   "source": [
    "def rle_encode(img):\n",
    "    '''\n",
    "    img: numpy array, 1 - foreground, 0 - background\n",
    "    Returns run length as string formatted\n",
    "    '''\n",
    "    pixels = img.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9kfiCuOxCGLM"
   },
   "source": [
    "Script for dividing training set and validation set. Create .txts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fWsIWtwc4K9p"
   },
   "outputs": [],
   "source": [
    "# plant = 'haricot' OR 'mais' OR 'all'\n",
    "# mode = 'all' OR 'bipbip' OR 'pead' OR 'roseau' OR 'weedelec'\n",
    "def split_set(base_dir = './Development_Dataset/Training', split = 0.2, plant = 'haricot', mode = 'all', is_test = False):\n",
    "    \n",
    "    plants = []\n",
    "    \n",
    "    if plant == 'all':\n",
    "        plants = ['haricot', 'mais']\n",
    "    else:\n",
    "        plants.append(plant)\n",
    "    \n",
    "    if not is_test:\n",
    "      datasets = []\n",
    "      files_ls = []\n",
    "    \n",
    "      if mode == 'all':\n",
    "          datasets.extend(['Bipbip', 'Pead', 'Roseau', 'Weedelec'])\n",
    "      else:\n",
    "          datasets.append(mode.capitalize())\n",
    "        \n",
    "      for dataset in datasets:\n",
    "        for p in plants:\n",
    "            images_dir = os.path.join(base_dir, dataset, p.capitalize(), 'Images')\n",
    "            files_ls_temp = os.listdir(images_dir)\n",
    "            files_ls.extend([filename.split('.')[0] + '\\n' for filename in files_ls_temp])\n",
    "            \n",
    "      shuffle(files_ls)\n",
    "          \n",
    "      final_element = int(len(files_ls) * split)\n",
    "      val_ls = files_ls[:final_element]\n",
    "      train_ls = files_ls[final_element:]\n",
    "      print('# images for training: ' + str(len(train_ls)))\n",
    "      print('# images for validation: ' + str(len(val_ls)))\n",
    "          \n",
    "      with open(os.path.join(base_dir,\"train.txt\"), \"w\") as train_txt:\n",
    "          train_txt.writelines(train_ls)\n",
    "          \n",
    "      with open(os.path.join(base_dir,\"val.txt\"), \"w\") as val_txt:\n",
    "          val_txt.writelines(val_ls)\n",
    "    \n",
    "    else:\n",
    "\n",
    "      datasets = []\n",
    "      datasets.extend(['Bipbip', 'Pead', 'Roseau', 'Weedelec'])\n",
    "\n",
    "      path = os.path.join(base_dir, \"temptest\")\n",
    "      if os.path.exists(path):\n",
    "        shutil.rmtree(path)\n",
    "      os.mkdir(path)\n",
    "    \n",
    "      plants = ['haricot', 'mais']\n",
    "\n",
    "      for pl in plants:\n",
    "        for dataset in datasets:\n",
    "          images_dir = os.path.join(base_dir, dataset, pl.capitalize(), 'Images')\n",
    "          files_ls_temp = os.listdir(images_dir)\n",
    "          for file in files_ls_temp:\n",
    "            shutil.copy(os.path.join(images_dir, file), path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for plotting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist(hist):\n",
    "    plt.plot(hist.history[\"iou_score\"])\n",
    "    plt.plot(hist.history[\"val_iou_score\"])\n",
    "    plt.plot(hist.history[loss_name])\n",
    "    plt.plot(hist.history[\"val_\" + loss_name])\n",
    "    plt.title(\"model IoU\")\n",
    "    plt.ylabel(\"score\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.legend([\"train_IoU\", \"val_IoU\", loss_name, \"val_\" + loss_name], loc=\"upper left\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s1bU_fkh3x4c"
   },
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CMg2bAT13v2L"
   },
   "outputs": [],
   "source": [
    "cwd = './'\n",
    "\n",
    "dataset_dir = \"Development_Dataset\"\n",
    "training_dir = os.path.join(dataset_dir, \"Training\")\n",
    "test_dir = os.path.join(dataset_dir, \"Test_Dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tcbblkg5Ck7R"
   },
   "outputs": [],
   "source": [
    "# Split train and validation sets\n",
    "split_set(base_dir= training_dir, mode=mode, plant=plant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GKykxOHBEZvG"
   },
   "source": [
    "Dictionary with array colors, used for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vg_-NFlGDXqE"
   },
   "outputs": [],
   "source": [
    "dict_rgb = {\n",
    "    \"background\" : [254, 124, 18],\n",
    "    \"crop\" : [255, 255, 255],\n",
    "    \"weed\" : [216, 67, 82]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "STv2Ug8TFGLM"
   },
   "source": [
    "Generator for creating imgs from patch dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lwTBRh_Bdz_c"
   },
   "outputs": [],
   "source": [
    "class CustomDataset(tf.keras.utils.Sequence):\n",
    "\n",
    "  def __init__(self, dataset_dir, which_subset, img_generator=None, mask_generator=None, \n",
    "               preprocessing_function=None, out_shape=[img_w, img_h]):\n",
    "    if which_subset == 'training':\n",
    "      subset_file = os.path.join(dataset_dir, 'train.txt')\n",
    "    elif which_subset == 'validation':\n",
    "      subset_file = os.path.join(dataset_dir, 'val.txt')\n",
    "    \n",
    "    with open(subset_file, 'r') as f:\n",
    "      lines = f.readlines()\n",
    "    \n",
    "    subset_filenames = []\n",
    "    for line in lines:\n",
    "      subset_filenames.append(line.strip()) \n",
    "\n",
    "    self.which_subset = which_subset\n",
    "    self.dataset_dir = dataset_dir\n",
    "    self.subset_filenames = subset_filenames\n",
    "    self.img_generator = img_generator\n",
    "    self.mask_generator = mask_generator\n",
    "    self.preprocessing_function = preprocessing_function\n",
    "    self.out_shape = out_shape\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.subset_filenames)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    \n",
    "    curr_filename = self.subset_filenames[index]\n",
    "    \n",
    "    split_filename = curr_filename.split('_')\n",
    "    curr_dataset = split_filename[0]\n",
    "    curr_plant = split_filename[1]\n",
    "    \n",
    "    if curr_dataset == 'Roseau':\n",
    "        img = Image.open(os.path.join(self.dataset_dir, curr_dataset, curr_plant.capitalize(), 'Images',\n",
    "                                      curr_filename + '.png'))\n",
    "    else:\n",
    "        img = Image.open(os.path.join(self.dataset_dir, curr_dataset, curr_plant.capitalize(), 'Images',\n",
    "                                      curr_filename + '.jpg'))\n",
    "    \n",
    "    mask = Image.fromarray(read_rgb_mask(os.path.join(self.dataset_dir, curr_dataset, curr_plant.capitalize(),\n",
    "                                                      'Masks', curr_filename + '.png')))\n",
    "\n",
    "    img = img.resize(self.out_shape)\n",
    "    mask = mask.resize(self.out_shape, resample=Image.NEAREST)\n",
    "\n",
    "    img_arr = np.array(img)\n",
    "    mask_arr = np.array(mask)\n",
    "\n",
    "    mask_arr = np.expand_dims(mask_arr, -1)\n",
    "    \n",
    "    out_mask = mask_arr\n",
    "    \n",
    "    if self.which_subset == 'training':\n",
    "      if self.img_generator is not None and self.mask_generator is not None:\n",
    "        \n",
    "        img_t = self.img_generator.get_random_transform(img_arr.shape)\n",
    "        img_arr = self.img_generator.apply_transform(img_arr, img_t)\n",
    "        \n",
    "        out_mask = np.zeros_like(mask_arr)\n",
    "        for c in np.unique(mask_arr):\n",
    "          if c > 0:\n",
    "            curr_class_arr = np.float32(mask_arr == c)\n",
    "            curr_class_arr = self.mask_generator.apply_transform(curr_class_arr, img_t)\n",
    "            \n",
    "            curr_class_arr = np.uint8(curr_class_arr)\n",
    "            \n",
    "            curr_class_arr = curr_class_arr * c \n",
    "            out_mask += curr_class_arr\n",
    "    else:\n",
    "      out_mask = mask_arr\n",
    "    \n",
    "    if self.preprocessing_function is not None:\n",
    "        img_arr = self.preprocessing_function(img_arr)\n",
    "\n",
    "    return img_arr, np.float32(out_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generators and Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I2yxw_KqFQGB"
   },
   "outputs": [],
   "source": [
    "# Create training ImageDataGenerator object\n",
    "# The commented transformations seemed to hurt performance\n",
    "if apply_data_augmentation:\n",
    "    img_data_gen = ImageDataGenerator(# rotation_range=10,\n",
    "                                      # width_shift_range=10,\n",
    "                                      # height_shift_range=10,\n",
    "                                      horizontal_flip=True,\n",
    "                                      vertical_flip=True,\n",
    "                                      fill_mode='reflect')\n",
    "    mask_data_gen = ImageDataGenerator(# rotation_range=10,\n",
    "                                       # width_shift_range=10,\n",
    "                                       # height_shift_range=10,\n",
    "                                       horizontal_flip=True,\n",
    "                                       vertical_flip=True,\n",
    "                                       fill_mode='reflect')\n",
    "else:\n",
    "    img_data_gen = ImageDataGenerator()\n",
    "    mask_data_gen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QzzizVKvFO2H"
   },
   "outputs": [],
   "source": [
    "preprocess_input = None\n",
    "\n",
    "dataset = CustomDataset(training_dir, 'training', \n",
    "                        img_generator=img_data_gen, mask_generator=mask_data_gen,\n",
    "                        preprocessing_function=preprocess_input)\n",
    "dataset_valid = CustomDataset(training_dir, 'validation', preprocessing_function=preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_generator(lambda: dataset,\n",
    "                                               output_types=(tf.float32, tf.float32),\n",
    "                                               output_shapes=([img_h, img_w, 3], [img_h, img_w, 1]))\n",
    "\n",
    "train_dataset = train_dataset.batch(bs)\n",
    "\n",
    "train_dataset = train_dataset.repeat()\n",
    "\n",
    "valid_dataset = tf.data.Dataset.from_generator(lambda: dataset_valid,\n",
    "                                               output_types=(tf.float32, tf.float32),\n",
    "                                               output_shapes=([img_h, img_w, 3], [img_h, img_w, 1]))\n",
    "valid_dataset = valid_dataset.batch(bs)\n",
    "\n",
    "valid_dataset = valid_dataset.repeat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_hyDs2EgFdeF"
   },
   "source": [
    "Visualize image and mask to be sure that all works well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CHwBxzaQFcyz"
   },
   "outputs": [],
   "source": [
    "iterator = iter(train_dataset)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "\n",
    "augmented_img, target = next(iterator)\n",
    "augmented_img = augmented_img[0]\n",
    "augmented_img = augmented_img\n",
    "\n",
    "print(augmented_img.shape, target.shape)\n",
    "target = np.array(target[0, ..., 0])\n",
    "\n",
    "print(np.unique(target))\n",
    "\n",
    "target_img = np.zeros([target.shape[0], target.shape[1], 3])\n",
    "\n",
    "target_img[np.where(target == 0)] = [0, 0, 0]\n",
    "\n",
    "class_names = [\"background\", \"crop\", \"weed\"]\n",
    "for i in range(1, 3):\n",
    "  target_img[np.where(target == i)] = np.array(dict_rgb[class_names[i]])\n",
    "\n",
    "ax[0].imshow(np.uint8(augmented_img))\n",
    "ax[1].imshow(np.uint8(target_img))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JA1TGlOMnFJM"
   },
   "source": [
    "## Convolutional Neural Network (CNN)\n",
    "### Encoder-Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "juGJoirUF34-"
   },
   "source": [
    "Preparing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(input_tensor, num_filters):\n",
    "  encoder = layers.Conv2D(num_filters, (3, 3), padding='same')(input_tensor)\n",
    "  encoder = layers.BatchNormalization()(encoder)\n",
    "  encoder = layers.Activation('relu')(encoder)\n",
    "  encoder = layers.Conv2D(num_filters, (3, 3), padding='same')(encoder)\n",
    "  encoder = layers.BatchNormalization()(encoder)\n",
    "  encoder = layers.Activation('relu')(encoder)\n",
    "  return encoder\n",
    "\n",
    "def encoder_block(input_tensor, num_filters):\n",
    "  encoder = conv_block(input_tensor, num_filters)\n",
    "  encoder_pool = layers.MaxPooling2D((2, 2), strides=(2, 2))(encoder)\n",
    "  \n",
    "  return encoder_pool, encoder\n",
    "\n",
    "def decoder_block(input_tensor, concat_tensor, num_filters):\n",
    "  decoder = layers.Conv2DTranspose(num_filters, (2, 2), strides=(2, 2), padding='same')(input_tensor)\n",
    "  decoder = layers.concatenate([concat_tensor, decoder], axis=-1)\n",
    "  decoder = layers.BatchNormalization()(decoder)\n",
    "  decoder = layers.Activation('relu')(decoder)\n",
    "  decoder = layers.Conv2D(num_filters, (3, 3), padding='same')(decoder)\n",
    "  decoder = layers.BatchNormalization()(decoder)\n",
    "  decoder = layers.Activation('relu')(decoder)\n",
    "  decoder = layers.Conv2D(num_filters, (3, 3), padding='same')(decoder)\n",
    "  decoder = layers.BatchNormalization()(decoder)\n",
    "  decoder = layers.Activation('relu')(decoder)\n",
    "  return decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras import layers\n",
    "from tensorflow.python.keras import models\n",
    "\n",
    "def create_model(depth, start_f, num_classes, img_shape = (224,224,3)):\n",
    "    inputs = layers.Input(shape=img_shape)\n",
    "    # 256\n",
    "\n",
    "    encoder0_pool, encoder0 = encoder_block(inputs, 32)\n",
    "    # 128\n",
    "\n",
    "    encoder1_pool, encoder1 = encoder_block(encoder0_pool, 64)\n",
    "    # 64\n",
    "\n",
    "    encoder2_pool, encoder2 = encoder_block(encoder1_pool, 128)\n",
    "    # 32\n",
    "\n",
    "    encoder3_pool, encoder3 = encoder_block(encoder2_pool, 256)\n",
    "    # 16\n",
    "\n",
    "    encoder4_pool, encoder4 = encoder_block(encoder3_pool, 512)\n",
    "    # 8\n",
    "\n",
    "    center = conv_block(encoder4_pool, 1024)\n",
    "    # center\n",
    "\n",
    "    decoder4 = decoder_block(center, encoder4, 512)\n",
    "    # 16\n",
    "\n",
    "    decoder3 = decoder_block(decoder4, encoder3, 256)\n",
    "    # 32\n",
    "\n",
    "    decoder2 = decoder_block(decoder3, encoder2, 128)\n",
    "    # 64\n",
    "\n",
    "    decoder1 = decoder_block(decoder2, encoder1, 64)\n",
    "    # 128\n",
    "\n",
    "    decoder0 = decoder_block(decoder1, encoder0, 32)\n",
    "    # 256\n",
    "\n",
    "    outputs = layers.Conv2D(3, (1, 1), activation='softmax')(decoder0)\n",
    "    model = models.Model(inputs=[inputs], outputs=[outputs])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k97OK6CRnFJS",
    "outputId": "985e6ff1-b03d-4677-842f-aaa86e1a1f8a"
   },
   "outputs": [],
   "source": [
    "model = create_model(depth=5, \n",
    "                     start_f=8, \n",
    "                     num_classes=3,\n",
    "                     img_shape = (img_w,img_h,3))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dice Coefficient as Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = tf.reshape(y_true, [-1])\n",
    "    y_pred_f = tf.reshape(y_pred, [-1])\n",
    "    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + 1e-8) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + 1e-8)\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    dice=0\n",
    "    y_true = tf.squeeze(y_true, -1)\n",
    "    for index in range(1, 3):\n",
    "        dice -= dice_coef(tf.cast(tf.where(y_true == index, 1, 0), tf.float32), tf.cast(y_pred[:,:,:,index], tf.float32))\n",
    "    return dice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Losses, Metrics and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GkyJIINNF3T1"
   },
   "outputs": [],
   "source": [
    "# Loss\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "IOUmetric = sm.metrics.IOUScore()\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "\n",
    "metrics = ['accuracy', IOUmetric]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UmIAAfeoGLKM"
   },
   "source": [
    "Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0kbOgjTpGImw"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "net = BACKBONE\n",
    "\n",
    "callbacks = []\n",
    "\n",
    "exps_dir = os.path.join(cwd, 'Training', 'Checkpoints', 'multiclass_segmentation_experiments' + net)\n",
    "if not os.path.exists(exps_dir):\n",
    "  os.makedirs(exps_dir)\n",
    "\n",
    "ckpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(exps_dir, 'weights'), \n",
    "                                                   save_weights_only=True, save_best_only=True)  # False to save the model directly\n",
    "\n",
    "callbacks.append(ckpt_callback)\n",
    "\n",
    "# Early Stopping\n",
    "es_callback = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10, mode='min')\n",
    "callbacks.append(es_callback)\n",
    "\n",
    "# Decay on Plateau\n",
    "decay_callback = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss', factor=decay, patience=5, verbose=1,\n",
    "    mode='min', min_lr=min_lr)\n",
    "callbacks.append(decay_callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NGVvRZIGHCK3"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qu933bx7HBn9",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hist = model.fit(x=train_dataset,\n",
    "                 epochs=100,\n",
    "                 steps_per_epoch=len(dataset),\n",
    "                 validation_data=valid_dataset,\n",
    "                 validation_steps=len(dataset_valid),\n",
    "                 callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist(hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IUAIn2mqHH2j"
   },
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZtpdawncHKPf"
   },
   "outputs": [],
   "source": [
    "# First create the generator for the test_set\n",
    "\n",
    "split_set(base_dir=test_dir, is_test = True)\n",
    "temptest = os.path.join(test_dir, \"temptest\")\n",
    "\n",
    "images = os.listdir(temptest)\n",
    "submission_dict = {}\n",
    "\n",
    "if len(images) > 0:\n",
    "  idx = 0\n",
    "  for img_name in images:\n",
    "\n",
    "    imgs = Image.open(os.path.join(temptest, img_name))\n",
    "    img_shp = imgs.size\n",
    "    img = imgs.resize([img_w, img_h], resample=Image.NEAREST)\n",
    "    img_arr = np.array(img)\n",
    "\n",
    "    out_sigmoid = model.predict(x=tf.expand_dims(img_arr, 0))\n",
    "\n",
    "    predicted_class = tf.argmax(out_sigmoid, -1)\n",
    "    mask_arr = predicted_class[0, ...]\n",
    "    mask_arr = np.array(mask_arr)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 3)\n",
    "    ax[0].imshow(np.uint8(mask_arr))\n",
    "\n",
    "    import cv2\n",
    "    mask_arr = cv2.resize(mask_arr, dsize=img_shp, interpolation=cv2.INTER_NEAREST)\n",
    "    ax[1].imshow(np.uint8(mask_arr))  \n",
    "    ax[2].imshow(np.uint8(imgs))    \n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    split_filename = img_name.split('_')\n",
    "    curr_dataset = split_filename[0]\n",
    "    curr_plant = split_filename[1]\n",
    "    curr_plant = curr_plant.capitalize()\n",
    "\n",
    "    img_name = os.path.splitext(img_name)\n",
    "    img_name = img_name[0]\n",
    "\n",
    "    submission_dict[img_name] = {}\n",
    "    submission_dict[img_name]['shape'] = img_shp\n",
    "    submission_dict[img_name]['team'] = curr_dataset\n",
    "    submission_dict[img_name]['crop'] = curr_plant\n",
    "    submission_dict[img_name]['segmentation'] = {}\n",
    "\n",
    "    # RLE encoding\n",
    "    # crop\n",
    "    rle_encoded_crop = rle_encode(mask_arr == 1)\n",
    "    # weed\n",
    "    rle_encoded_weed = rle_encode(mask_arr == 2)\n",
    "\n",
    "    submission_dict[img_name]['segmentation']['crop'] = rle_encoded_crop\n",
    "    submission_dict[img_name]['segmentation']['weed'] = rle_encoded_weed\n",
    "\n",
    "# Finally, save the results into the submission.json file\n",
    "import json\n",
    "with open('submission.json', 'w+') as f:\n",
    "    json.dump(submission_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "zipfile.ZipFile('submission.zip', mode='w').write(\"submission.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Top_Patches.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
