{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8itnFnnx3ntq"
   },
   "source": [
    "# Initializations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tOBDSA9BnFIx"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "from numpy.random import shuffle\n",
    "import shutil\n",
    "import patchify as p\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import time\n",
    "from matplotlib import cm\n",
    "import segmentation_models as sm\n",
    "\n",
    "# Set the seed for random operations. \n",
    "# This let our experiments to be reproducible. \n",
    "SEED = 1234\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gpu in tf.config.experimental.list_physical_devices('GPU'):\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sh5NWR_0DceA"
   },
   "source": [
    "# Hyperparameter Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bCYwTG9lDcId"
   },
   "outputs": [],
   "source": [
    "img_w, img_h = 512, 512\n",
    "win_size = img_w # for tiling\n",
    "\n",
    "# Optimization params\n",
    "bs = 8\n",
    "lr = 1e-3\n",
    "decay = 0.1\n",
    "min_lr = 1e-6\n",
    "\n",
    "# Percentage of tolerated 0 pixel in mask in patches of validation and training\n",
    "exclude_val = 1.01 # NON TOLERATED\n",
    "exclude_train = 0.991 # ALL BLACK NON TOLERATED\n",
    "\n",
    "# freeze encoder: True -> encoder freezed\n",
    "block_layers = True\n",
    "\n",
    "apply_data_augmentation = True\n",
    "\n",
    "mode = \"all\"\n",
    "plant = \"mais\"\n",
    "\n",
    "BACKBONE = \"vgg16\"\n",
    "\n",
    "loss_name = \"loss\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1YT1i2asB8iz"
   },
   "source": [
    "# Script Comprehension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YKYjoayM4Vhy"
   },
   "source": [
    "Converting in classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2QI3ABYWp4HR"
   },
   "outputs": [],
   "source": [
    "# Converts images to RGB to Target\n",
    "def read_rgb_mask(img_path):\n",
    "    '''\n",
    "    img_path: path to the mask file\n",
    "    Returns the numpy array containing target values\n",
    "    '''\n",
    "\n",
    "    mask_img = Image.open(img_path)\n",
    "    mask_arr = np.array(mask_img)\n",
    "\n",
    "    new_mask_arr = np.zeros(mask_arr.shape[:2], dtype=mask_arr.dtype)\n",
    "\n",
    "    # Use RGB dictionary in 'RGBtoTarget.txt' to convert RGB to target\n",
    "    new_mask_arr[np.where(np.all(mask_arr == [216, 124, 18], axis=-1))] = 0\n",
    "    new_mask_arr[np.where(np.all(mask_arr == [255, 255, 255], axis=-1))] = 1\n",
    "    new_mask_arr[np.where(np.all(mask_arr == [216, 67, 82], axis=-1))] = 2\n",
    "\n",
    "    return new_mask_arr\n",
    "\n",
    "def mask_to_rgb(mask_arr):\n",
    "\n",
    "    mask = np.squeeze(mask_arr, axis=2)\n",
    "    new_mask_arr = np.zeros((mask_arr.shape[0], mask_arr.shape[1], 3), dtype=mask_arr.dtype)\n",
    "\n",
    "    new_mask_arr[np.where(mask == 0)] = np.array([0, 0, 0])\n",
    "    new_mask_arr[np.where(mask == 1)] = np.array([255, 255, 255])\n",
    "    new_mask_arr[np.where(mask == 2)] = np.array([216, 67, 82])\n",
    "\n",
    "    return new_mask_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fTlvojWQHlfn"
   },
   "source": [
    "RLE Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j6vBas5xHk8Z"
   },
   "outputs": [],
   "source": [
    "def rle_encode(img):\n",
    "    '''\n",
    "    img: numpy array, 1 - foreground, 0 - background\n",
    "    Returns run length as string formatted\n",
    "    '''\n",
    "    pixels = img.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9kfiCuOxCGLM"
   },
   "source": [
    "Script for dividing training set and validation set. Create .txts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fWsIWtwc4K9p"
   },
   "outputs": [],
   "source": [
    "# plant = 'haricot' OR 'mais' OR 'all'\n",
    "# mode = 'all' OR 'bipbip' OR 'pead' OR 'roseau' OR 'weedelec'\n",
    "def split_set(base_dir = './Development_Dataset/Training', split = 0.2, plant = 'haricot', mode = 'all', is_test = False):\n",
    "    \n",
    "    plants = []\n",
    "    \n",
    "    if plant == 'all':\n",
    "        plants = ['haricot', 'mais']\n",
    "    else:\n",
    "        plants.append(plant)\n",
    "    \n",
    "    if not is_test:\n",
    "      datasets = []\n",
    "      files_ls = []\n",
    "    \n",
    "      if mode == 'all':\n",
    "          datasets.extend(['Bipbip', 'Pead', 'Roseau', 'Weedelec'])\n",
    "      else:\n",
    "          datasets.append(mode.capitalize())\n",
    "        \n",
    "      for dataset in datasets:\n",
    "        for p in plants:\n",
    "            images_dir = os.path.join(base_dir, dataset, p.capitalize(), 'Images')\n",
    "            files_ls_temp = os.listdir(images_dir)\n",
    "            files_ls.extend([filename.split('.')[0] + '\\n' for filename in files_ls_temp])\n",
    "            \n",
    "      shuffle(files_ls)\n",
    "          \n",
    "      final_element = int(len(files_ls) * split)\n",
    "      val_ls = files_ls[:final_element]\n",
    "      train_ls = files_ls[final_element:]\n",
    "      print('# images for training: ' + str(len(train_ls)))\n",
    "      print('# images for validation: ' + str(len(val_ls)))\n",
    "          \n",
    "      with open(os.path.join(base_dir,\"train.txt\"), \"w\") as train_txt:\n",
    "          train_txt.writelines(train_ls)\n",
    "          \n",
    "      with open(os.path.join(base_dir,\"val.txt\"), \"w\") as val_txt:\n",
    "          val_txt.writelines(val_ls)\n",
    "    \n",
    "    else:\n",
    "\n",
    "      datasets = []\n",
    "      datasets.extend(['Bipbip', 'Pead', 'Roseau', 'Weedelec'])\n",
    "\n",
    "      path = os.path.join(base_dir, \"temptest\")\n",
    "      if os.path.exists(path):\n",
    "        shutil.rmtree(path)\n",
    "      os.mkdir(path)\n",
    "    \n",
    "      plants = ['haricot', 'mais']\n",
    "\n",
    "      for pl in plants:\n",
    "        for dataset in datasets:\n",
    "          images_dir = os.path.join(base_dir, dataset, pl.capitalize(), 'Images')\n",
    "          files_ls_temp = os.listdir(images_dir)\n",
    "          for file in files_ls_temp:\n",
    "            shutil.copy(os.path.join(images_dir, file), path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "czvLV_c8i0xo"
   },
   "source": [
    "Code for tiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1sJnaDM0i0f1"
   },
   "outputs": [],
   "source": [
    "def produce_patches(img_o, mask_o, window_size, step = 20, with_pad = True):\n",
    "  # From img get array of patches\n",
    "  # From mask get array of patches\n",
    "  # window_size = size of a patch\n",
    "  # step = stride\n",
    "  # with_pad = Adds pad for precise recostruction\n",
    "\n",
    "  img_patches = None\n",
    "  mask_patches = None\n",
    "\n",
    "  img = None\n",
    "  mask = None\n",
    "  pads = None\n",
    "  if with_pad:\n",
    "    if img_o is not None:\n",
    "      # Prepare image in case not proportional step\n",
    "      diff = np.array([img_o.shape[0] - window_size, img_o.shape[1] - window_size])\n",
    "      # Since we need exact patches... padding!\n",
    "      times = np.ceil(diff/step)\n",
    "      dims = np.multiply([step, step], times)\n",
    "      pads = window_size+dims-np.array(img_o.shape[:2])\n",
    "      img = np.pad(img_o, ((0, int(pads[0])), (0, int(pads[1])), (0, 0)), 'constant')\n",
    "    if mask_o is not None:\n",
    "      # Prepare image in case not proportional step\n",
    "      diff = np.array([mask_o.shape[0] - window_size, mask_o.shape[1] - window_size])\n",
    "      # Since we need exact patches... padding!\n",
    "      times = np.ceil(diff/step)\n",
    "      dims = np.multiply([step, step], times)\n",
    "      pads = window_size+dims-np.array(mask_o.shape[:2])\n",
    "      mask = np.pad(mask_o, ((0, int(pads[0])), (0, int(pads[1])), (0, 0)), 'constant')\n",
    "  else:\n",
    "    img = img_o\n",
    "    mask = mask_o\n",
    "\n",
    "  if img is not None:\n",
    "    img_patches = []\n",
    "    img_patches_result = p.patchify(img, (window_size, window_size, 3), step=step)\n",
    "    for w in range(img_patches_result.shape[0]):\n",
    "      for h in range(img_patches_result.shape[1]):\n",
    "        img_patches.append(img_patches_result[w, h, 0])\n",
    "    img_patches = np.array(img_patches)\n",
    "  if mask is not None:\n",
    "    mask_patches = []\n",
    "    mask_patches_result = p.patchify(mask, (window_size, window_size, 1), step=step)\n",
    "    for w in range(mask_patches_result.shape[0]):\n",
    "      for h in range(mask_patches_result.shape[1]):\n",
    "        mask_patches.append(mask_patches_result[w, h, 0])\n",
    "    mask_patches = np.array(mask_patches)\n",
    "\n",
    "  return img_patches, mask_patches, pads\n",
    "\n",
    "def restore_with_interp(img_pa, or_shape, win_size, step, wi, hi):\n",
    "    #Recostruct from patches\n",
    "    # or_shape = original shape with len 3\n",
    "    # win_size = window_size\n",
    "    # step = step\n",
    "    # wi = number of patches row wise\n",
    "    # he = number of patches height wise\n",
    "    \n",
    "    i = 0\n",
    "    margin = win_size - step\n",
    "    if len(or_shape) == 2:\n",
    "      raise Exception(\"or_shape must be 3D\")\n",
    "    result = np.zeros(or_shape, np.float32)\n",
    "\n",
    "    dtype = img_pa.dtype\n",
    "\n",
    "    img_p = None\n",
    "    if dtype != np.float32:\n",
    "      img_p = img_pa.astype(np.float32)\n",
    "    else:\n",
    "      img_p = img_pa\n",
    "\n",
    "    for w in range(wi):\n",
    "      for h in range(hi):\n",
    "        result[w*win_size-w*margin:(w+1)*win_size-w*margin, h*win_size-h*margin:(h+1)*win_size-h*margin] += img_p[i]\n",
    "        i+=1\n",
    "\n",
    "    for w in range(wi):\n",
    "      for h in range(hi):\n",
    "        if w == 0:\n",
    "          result[0:margin, step*(h+1):step*(h+1)+margin] /= 2\n",
    "        result[w*step+margin:(w+1)*step, step*(h+1):step*(h+1)+margin] /= 2\n",
    "\n",
    "    for h in range(wi):\n",
    "      for w in range(hi):\n",
    "        if h == 0:\n",
    "          result[step*(w+1):step*(w+1)+margin, 0:margin] /= 2\n",
    "        result[step*(w+1):step*(w+1)+margin, h*step+margin:(h+1)*step] /= 2\n",
    "\n",
    "    for w in range(1,wi):\n",
    "      for h in range(1,hi):\n",
    "        result[win_size*w-margin*w:win_size*w-margin*(w-1), win_size*h-margin*h:win_size*h-margin*(h-1)] /= 4\n",
    "\n",
    "    if dtype != np.float32:\n",
    "      result = result.astype(dtype)\n",
    "      \n",
    "    return result\n",
    "  \n",
    "def reconstruct_patches(img_patches, mask_patches, or_shape, pads, step=20):\n",
    "  # From img patches get img\n",
    "  # From mask patches get mask\n",
    "  # or_shape = [width, height] like of original image\n",
    "  # step = stride7\n",
    "\n",
    "  restoring = or_shape\n",
    "  channel = or_shape[2]\n",
    "  or_shape = np.uint(np.array(or_shape[:2]) + pads)\n",
    "  or_shape = [or_shape[0], or_shape[1], channel]\n",
    "\n",
    "  # Values for restoration\n",
    "  win_size = img_patches.shape[1]\n",
    "  \n",
    "  img = None\n",
    "  mask = None\n",
    "  if img_patches is not None:\n",
    "    wh = img_patches.shape[0]\n",
    "    wi = int((or_shape[0] - img_patches.shape[1])//step + 1)\n",
    "    he = int((or_shape[1] - img_patches.shape[2])//step + 1)\n",
    "    if wh != he * wi:\n",
    "      raise Exception(\"hw != h*w\")\n",
    "    \n",
    "    img = restore_with_interp(img_patches, or_shape, win_size, step, wi, he)\n",
    "    img = img[:restoring[0],:restoring[1]]\n",
    "\n",
    "  if mask_patches is not None:\n",
    "    wh = mask_patches.shape[0]\n",
    "    wi = int((or_shape[0] - mask_patches.shape[1])//step + 1)\n",
    "    he = int((or_shape[1] - mask_patches.shape[2])//step + 1)\n",
    "    if wh != hi * we:\n",
    "      raise Exception(\"hw != h*w\")\n",
    "      \n",
    "    mask = restore_with_interp(mask_patches, or_shape, win_size, step, wi, he)\n",
    "    mask = mask[:restoring[0],:restoring[1]]\n",
    "  return img, mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vyPQb48XCt-k"
   },
   "source": [
    "Code used for counting number of pixel in mask. Optimized to be fast. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0eDcOCgKqJfS"
   },
   "outputs": [],
   "source": [
    "# Return a dictionary of distinct values of mask\n",
    "def f_pp(mask, nmax=1000):\n",
    "    iai32 = mask.ravel()\n",
    "    colors = list(set(iai32))\n",
    "    counts = []\n",
    "    match = None\n",
    "    for i in range(0, len(colors)):\n",
    "        counts.append(0)\n",
    "        match = iai32 == colors[i]\n",
    "        counts[i] = np.count_nonzero(match)\n",
    "    colors = [np.uint8(col) for col in colors]\n",
    "    return {a[0] : a[1] for a in zip(colors, counts)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OQtgaurxC23P"
   },
   "source": [
    "Utility script to save the patch in a folder and having them swiftly prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gg_FD9Z677S8"
   },
   "outputs": [],
   "source": [
    "def save_patch(save_fld, sub, dat_dir, win_size, exclude = 0.95):\n",
    "  # This method create patches for entire dataset and save it in a folder\n",
    "  # A text file with all the images is also created.\n",
    "\n",
    "  subset_file = None\n",
    "  if sub == 'training':\n",
    "      subset_file = os.path.join(dat_dir, 'train.txt')\n",
    "  elif sub == 'validation':\n",
    "      subset_file = os.path.join(dat_dir, 'val.txt')\n",
    "    \n",
    "  with open(subset_file, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "  subset_filenames = []\n",
    "  for line in lines:\n",
    "    subset_filenames.append(line.strip())\n",
    "  \n",
    "  image_names = []\n",
    "  folder = \"Images\"\n",
    "  folder_m = \"Masks\"\n",
    "\n",
    "  if os.path.exists(save_fld):\n",
    "    shutil.rmtree(save_fld)\n",
    "  os.makedirs(save_fld)\n",
    "  os.makedirs(os.path.join(save_fld, folder))\n",
    "  os.makedirs(os.path.join(save_fld, folder_m))\n",
    "  \n",
    "  for i in range(0, len(subset_filenames)):\n",
    "    curr_filename = subset_filenames[i]\n",
    "    split_filename = curr_filename.split('_')\n",
    "    curr_dataset = split_filename[0]\n",
    "    curr_plant = split_filename[1]\n",
    "    \n",
    "    if curr_dataset == 'Roseau':\n",
    "        img = Image.open(os.path.join(dat_dir, curr_dataset, curr_plant.capitalize(), 'Images',\n",
    "                                      curr_filename + '.png'))\n",
    "    else:\n",
    "        img = Image.open(os.path.join(dat_dir, curr_dataset, curr_plant.capitalize(), 'Images',\n",
    "                                      curr_filename + '.jpg'))\n",
    "    \n",
    "    mask = Image.fromarray(read_rgb_mask(os.path.join(dat_dir, curr_dataset, curr_plant.capitalize(),\n",
    "                                                      'Masks', curr_filename + '.png')))\n",
    "\n",
    "    img_arr = np.array(img)\n",
    "    mask_arr = np.array(mask)\n",
    "    mask_arr = np.expand_dims(mask_arr, -1)\n",
    "    \n",
    "    # We put WITH_PAD = FALSE in order to avoid creating overlapping images in training.\n",
    "    # This is done because introducing overlapping images would cause redundancy.\n",
    "    img_p, mask_p, _ = produce_patches(img_arr, mask_arr, win_size, step=win_size, with_pad=False)\n",
    "    img_arr = []\n",
    "    mask_arr = []\n",
    "    sum = win_size*win_size\n",
    "    for j in range(0, mask_p.shape[0]):\n",
    "      dict_colors = f_pp(mask_p[j])\n",
    "      if dict_colors.get(0, 0) < sum*exclude:\n",
    "         filename = \"img_\" + str(len(image_names)) + \".png\"\n",
    "         img = Image.fromarray(img_p[j])\n",
    "         mask = Image.fromarray(mask_to_rgb(mask_p[j]))\n",
    "         img.save(os.path.join(save_fld, folder, filename))\n",
    "         mask.save(os.path.join(save_fld, folder_m, filename))\n",
    "         image_names.append(filename + '\\n')\n",
    "    print(i+1, \"images processed. Still: \", len(subset_filenames)-i-1)\n",
    "  with open(os.path.join(save_fld,\"img.txt\"), \"w\") as val_txt:\n",
    "    val_txt.writelines(image_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for plotting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist(hist):\n",
    "    plt.plot(hist.history[\"iou_score\"])\n",
    "    plt.plot(hist.history[\"val_iou_score\"])\n",
    "    plt.plot(hist.history[loss_name])\n",
    "    plt.plot(hist.history[\"val_\" + loss_name])\n",
    "    plt.title(\"model IoU\")\n",
    "    plt.ylabel(\"score\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.legend([\"train_IoU\", \"val_IoU\", loss_name, \"val_\" + loss_name], loc=\"upper left\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s1bU_fkh3x4c"
   },
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CMg2bAT13v2L"
   },
   "outputs": [],
   "source": [
    "cwd = './'\n",
    "\n",
    "dataset_dir = \"Development_Dataset\"\n",
    "training_dir = os.path.join(dataset_dir, \"Training\")\n",
    "test_dir = os.path.join(dataset_dir, \"Test_Dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tcbblkg5Ck7R"
   },
   "outputs": [],
   "source": [
    "# Split train and validation sets\n",
    "split_set(base_dir= training_dir, mode=mode, plant=plant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4s94p35DDBuo",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create and save patches (if not already created)\n",
    "path_val = os.path.join(dataset_dir, \"Training\", \"Patches\", \"Subdivided_val\", mode, plant, str(win_size))\n",
    "path_train = os.path.join(dataset_dir, \"Training\", \"Patches\", \"Subdivided\", mode, plant, str(win_size))\n",
    "\n",
    "if not os.path.exists(path_train):\n",
    "  save_patch(path_train, 'training', training_dir, win_size=win_size, exclude=exclude_train)\n",
    "if not os.path.exists(path_val):\n",
    "  save_patch(path_val, 'validation', training_dir, win_size=win_size, exclude=exclude_val) # Do not exclude anything"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GKykxOHBEZvG"
   },
   "source": [
    "Dictionary with array colors, used for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vg_-NFlGDXqE"
   },
   "outputs": [],
   "source": [
    "dict_rgb = {\n",
    "    \"background\" : [254, 124, 18],\n",
    "    \"crop\" : [255, 255, 255],\n",
    "    \"weed\" : [216, 67, 82]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "STv2Ug8TFGLM"
   },
   "source": [
    "Generator for creating imgs from patch dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lwTBRh_Bdz_c"
   },
   "outputs": [],
   "source": [
    "# Patches Generator\n",
    "class create_generator(tf.keras.utils.Sequence):\n",
    "\n",
    "  def __init__(self, dataset_dir, which_subset, img_generator=None, mask_generator=None, \n",
    "               preprocessing_function=None):\n",
    "    subset_file = os.path.join(dataset_dir, 'img.txt')\n",
    "    \n",
    "    with open(subset_file, 'r') as f:\n",
    "      lines = f.readlines()\n",
    "    \n",
    "    subset_filenames = []\n",
    "    for line in lines:\n",
    "      subset_filenames.append(line.strip()) \n",
    "\n",
    "    self.which_subset = which_subset\n",
    "    self.dataset_dir = dataset_dir\n",
    "    self.subset_filenames = subset_filenames\n",
    "    self.img_generator = img_generator\n",
    "    self.mask_generator = mask_generator\n",
    "    self.preprocessing_function = preprocessing_function\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.subset_filenames)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    return self.__data__generation(index)\n",
    "        \n",
    "  def __data__generation(self, index):\n",
    "    \n",
    "    if index >= len(self.subset_filenames):\n",
    "      return None, None\n",
    "    curr_filename = self.subset_filenames[index]\n",
    "    \n",
    "    img = Image.open(os.path.join(self.dataset_dir, 'Images',\n",
    "                                      curr_filename))\n",
    "    mask = Image.fromarray(read_rgb_mask(os.path.join(self.dataset_dir, 'Masks',\n",
    "                                      curr_filename)))\n",
    "\n",
    "    img_arr = np.array(img)\n",
    "    mask_arr = np.array(mask)\n",
    "    \n",
    "    if len(mask_arr.shape) == 2: \n",
    "      mask_arr = np.expand_dims(mask_arr, -1)\n",
    "\n",
    "    out_mask = None\n",
    "\n",
    "    if self.which_subset == 'training':\n",
    "      if self.img_generator is not None and self.mask_generator is not None:\n",
    "        \n",
    "        # No SEED because it would generate the same transformation at every epoch\n",
    "        img_t = self.img_generator.get_random_transform(img_arr.shape)\n",
    "        img_arr = self.img_generator.apply_transform(img_arr, img_t)\n",
    "        \n",
    "        out_mask = np.zeros_like(mask_arr)\n",
    "        for c in np.unique(mask_arr):\n",
    "          if c > 0:\n",
    "            curr_class_arr = np.float32(mask_arr == c)\n",
    "            curr_class_arr = self.mask_generator.apply_transform(curr_class_arr, img_t)\n",
    "            \n",
    "            curr_class_arr = np.uint8(curr_class_arr)\n",
    "            \n",
    "            curr_class_arr = curr_class_arr * c \n",
    "            out_mask += curr_class_arr\n",
    "    else:\n",
    "      out_mask = mask_arr\n",
    "    \n",
    "    if self.preprocessing_function is not None:\n",
    "        img_arr = self.preprocessing_function(img_arr)\n",
    "      \n",
    "    return img_arr, np.float32(out_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generators and Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I2yxw_KqFQGB"
   },
   "outputs": [],
   "source": [
    "preprocess_input = tf.keras.applications.vgg16.preprocess_input\n",
    "\n",
    "# Create training ImageDataGenerator object\n",
    "# The commented transformations seemed to hurt performance\n",
    "if apply_data_augmentation:\n",
    "    img_data_gen = ImageDataGenerator(# rotation_range=10,\n",
    "                                      # width_shift_range=10,\n",
    "                                      # height_shift_range=10,\n",
    "                                      horizontal_flip=True,\n",
    "                                      vertical_flip=True,\n",
    "                                      fill_mode='reflect')\n",
    "    mask_data_gen = ImageDataGenerator(# rotation_range=10,\n",
    "                                       # width_shift_range=10,\n",
    "                                       # height_shift_range=10,\n",
    "                                       horizontal_flip=True,\n",
    "                                       vertical_flip=True,\n",
    "                                       fill_mode='reflect')\n",
    "else:\n",
    "    img_data_gen = ImageDataGenerator()\n",
    "    mask_data_gen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QzzizVKvFO2H"
   },
   "outputs": [],
   "source": [
    "train_gen = create_generator(path_train, 'training', \n",
    "                          img_generator=img_data_gen, \n",
    "                          mask_generator=mask_data_gen,\n",
    "                          preprocessing_function = preprocess_input)\n",
    "valid_gen = create_generator(path_val, 'validation',\n",
    "                          preprocessing_function = preprocess_input)\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_generator(lambda: train_gen,\n",
    "                                               output_types=(tf.float32, tf.float32),\n",
    "                                               output_shapes=([img_h, img_w, 3], [img_h, img_w, 1]))\n",
    "\n",
    "train_dataset = train_dataset.batch(bs)\n",
    "\n",
    "train_dataset = train_dataset.repeat()\n",
    "\n",
    "valid_dataset = tf.data.Dataset.from_generator(lambda: valid_gen,\n",
    "                                               output_types=(tf.float32, tf.float32),\n",
    "                                               output_shapes=([img_h, img_w, 3], [img_h, img_w, 1]))\n",
    "valid_dataset = valid_dataset.batch(bs)\n",
    "\n",
    "valid_dataset = valid_dataset.repeat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_hyDs2EgFdeF"
   },
   "source": [
    "Visualize image and mask to be sure that all works well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CHwBxzaQFcyz"
   },
   "outputs": [],
   "source": [
    "iterator = iter(train_dataset)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "\n",
    "augmented_img, target = next(iterator)\n",
    "augmented_img = augmented_img[0]\n",
    "augmented_img = augmented_img\n",
    "\n",
    "print(augmented_img.shape, target.shape)\n",
    "target = np.array(target[0, ..., 0])\n",
    "\n",
    "print(np.unique(target))\n",
    "\n",
    "target_img = np.zeros([target.shape[0], target.shape[1], 3])\n",
    "\n",
    "target_img[np.where(target == 0)] = [0, 0, 0]\n",
    "\n",
    "class_names = [\"background\", \"crop\", \"weed\"]\n",
    "for i in range(1, 3):\n",
    "  target_img[np.where(target == i)] = np.array(dict_rgb[class_names[i]])\n",
    "\n",
    "ax[0].imshow(np.uint8(augmented_img))\n",
    "ax[1].imshow(np.uint8(target_img))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JA1TGlOMnFJM"
   },
   "source": [
    "## Convolutional Neural Network (CNN)\n",
    "### Encoder-Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "juGJoirUF34-"
   },
   "source": [
    "Preparing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape, num_classes=3, weights = None, blocked=1):\n",
    "    \n",
    "    start_f=256\n",
    "    \n",
    "    model = tf.keras.Sequential()\n",
    "    \n",
    "    # Encoder\n",
    "    vgg = tf.keras.applications.VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    model.add(vgg)\n",
    "            \n",
    "    # Decoder\n",
    "    for i in range(5):\n",
    "        model.add(tf.keras.layers.UpSampling2D(2, interpolation='bilinear'))\n",
    "        model.add(tf.keras.layers.Conv2D(filters=start_f,\n",
    "                                         kernel_size=(3, 3),\n",
    "                                         strides=(1, 1),\n",
    "                                         padding='same'))\n",
    "        model.add(tf.keras.layers.ReLU())\n",
    "\n",
    "        start_f = start_f // 2\n",
    "\n",
    "    # Prediction Layer\n",
    "    model.add(tf.keras.layers.Conv2D(filters=num_classes,\n",
    "                                     kernel_size=(1, 1),\n",
    "                                     strides=(1, 1),\n",
    "                                     padding='same',\n",
    "                                     activation='softmax'))\n",
    "    \n",
    "    if weights is not None:\n",
    "      model.load_weights(weights)\n",
    "      for layer in vgg.layers:\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        if blocked:\n",
    "            for layer in vgg.layers:\n",
    "                layer.trainable = False\n",
    "        else:\n",
    "            for layer in vgg.layers:\n",
    "                layer.trainable = True\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k97OK6CRnFJS",
    "outputId": "985e6ff1-b03d-4677-842f-aaa86e1a1f8a"
   },
   "outputs": [],
   "source": [
    "model = create_model(num_classes=3,\n",
    "                     input_shape=(img_h, img_w, 3),\n",
    "                     blocked=block_layers)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dice Coefficient as Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = tf.reshape(y_true, [-1])\n",
    "    y_pred_f = tf.reshape(y_pred, [-1])\n",
    "    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + 1e-8) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + 1e-8)\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    dice=0\n",
    "    y_true = tf.squeeze(y_true, -1)\n",
    "    for index in range(1, 3):\n",
    "        dice -= dice_coef(tf.cast(tf.where(y_true == index, 1, 0), tf.float32), tf.cast(y_pred[:,:,:,index], tf.float32))\n",
    "    return dice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Losses, Metrics and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GkyJIINNF3T1"
   },
   "outputs": [],
   "source": [
    "# Loss\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "IOUmetric = sm.metrics.IOUScore()\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "\n",
    "metrics = ['accuracy', IOUmetric]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UmIAAfeoGLKM"
   },
   "source": [
    "Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0kbOgjTpGImw"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "net = BACKBONE\n",
    "\n",
    "callbacks = []\n",
    "\n",
    "exps_dir = os.path.join(cwd, 'Training', 'Checkpoints', 'multiclass_segmentation_experiments' + net)\n",
    "if not os.path.exists(exps_dir):\n",
    "  os.makedirs(exps_dir)\n",
    "\n",
    "ckpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(exps_dir, 'weights'), \n",
    "                                                   save_weights_only=True, save_best_only=True)  # False to save the model directly\n",
    "\n",
    "callbacks.append(ckpt_callback)\n",
    "\n",
    "# Early Stopping\n",
    "es_callback = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10, mode='min')\n",
    "callbacks.append(es_callback)\n",
    "\n",
    "# Decay on Plateau\n",
    "decay_callback = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss', factor=decay, patience=5, verbose=1,\n",
    "    mode='min', min_lr=min_lr)\n",
    "callbacks.append(decay_callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NGVvRZIGHCK3"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qu933bx7HBn9",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hist = model.fit(x=train_dataset,\n",
    "                 epochs=100,\n",
    "                 steps_per_epoch=len(train_gen)//bs,\n",
    "                 validation_data=valid_dataset,\n",
    "                 validation_steps=len(valid_gen)//bs,\n",
    "                 callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist(hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IUAIn2mqHH2j"
   },
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZtpdawncHKPf"
   },
   "outputs": [],
   "source": [
    "# First create the generator for the test_set\n",
    "\n",
    "# Step = stride of patches\n",
    "# Set step = win_size-4 to create patches with an overlapping border of width = 4\n",
    "step = win_size-4\n",
    "\n",
    "split_set(base_dir=test_dir, is_test = True)\n",
    "temptest = os.path.join(test_dir, \"temptest\")\n",
    "\n",
    "images = os.listdir(temptest)\n",
    "submission_dict = {}\n",
    "\n",
    "net = BACKBONE\n",
    "exps_dir = os.path.join(cwd, 'Training', 'Checkpoints', 'multiclass_segmentation_experiments' + net)\n",
    "filepath = os.path.join(exps_dir, 'weights')\n",
    "\n",
    "model.load_weights(filepath)\n",
    "\n",
    "if len(images) > 0:\n",
    "  idx = 0\n",
    "  for img_name in images:\n",
    "\n",
    "    imgs = Image.open(os.path.join(temptest, img_name))\n",
    "    img_arr = np.array(imgs)\n",
    "    or_shape = img_arr.shape\n",
    "\n",
    "    predictions_m = []\n",
    "    \n",
    "    # pads is the number of pixels added to the original image for zero-padding.\n",
    "    # Needed to obtain an integer number of patches.\n",
    "    # The padding is removed for the final prediction.\n",
    "    img_p, _, pads = produce_patches(img_arr, None, win_size, step = step)\n",
    "  \n",
    "    for i in range(img_p.shape[0]):\n",
    "        out_sigmoid = model.predict(x=tf.expand_dims(img_p[i], axis=0))\n",
    "        predictions_m.append(out_sigmoid)\n",
    "\n",
    "    predictions_m = np.concatenate(predictions_m, axis = 0)\n",
    "    # Only replace step\n",
    "    predicted_class, _ = reconstruct_patches(predictions_m, None, or_shape, pads, step=step)\n",
    "    print(predicted_class.shape)\n",
    "    # Get predicted class as the index corresponding to the maximum value in the vector probability\n",
    "    # predicted_class = tf.cast(out_sigmoid > score_th, tf.int32)\n",
    "    # predicted_class = predicted_class[0, ..., 0]\n",
    "    predicted_class = tf.argmax(predicted_class, -1)\n",
    "    mask_arr = predicted_class\n",
    "    mask_arr = np.array(mask_arr)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    split_filename = img_name.split('_')\n",
    "    curr_dataset = split_filename[0]\n",
    "    curr_plant = split_filename[1]\n",
    "    curr_plant = curr_plant.capitalize()\n",
    "\n",
    "    img_name = os.path.splitext(img_name)\n",
    "    img_name = img_name[0]\n",
    "\n",
    "    submission_dict[img_name] = {}\n",
    "    submission_dict[img_name]['shape'] = or_shape\n",
    "    submission_dict[img_name]['team'] = curr_dataset\n",
    "    submission_dict[img_name]['crop'] = curr_plant\n",
    "    submission_dict[img_name]['segmentation'] = {}\n",
    "\n",
    "    # RLE encoding\n",
    "    # crop\n",
    "    rle_encoded_crop = rle_encode(mask_arr == 1)\n",
    "    # weed\n",
    "    rle_encoded_weed = rle_encode(mask_arr == 2)\n",
    "\n",
    "    submission_dict[img_name]['segmentation']['crop'] = rle_encoded_crop\n",
    "    submission_dict[img_name]['segmentation']['weed'] = rle_encoded_weed\n",
    "\n",
    "\n",
    "# Finally, save the results into the submission.json file\n",
    "import json\n",
    "with open('submission.json', 'w') as f:\n",
    "    json.dump(submission_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "zipfile.ZipFile('submission.zip', mode='w').write(\"submission.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Top_Patches.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
