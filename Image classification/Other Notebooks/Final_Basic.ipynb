{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PHMIEYftB3iq"
   },
   "source": [
    "# Imports and Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7vxN_r5nBexQ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Model\n",
    "import os\n",
    "import shutil\n",
    "import csv\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QQ0nuMBZBoMj"
   },
   "outputs": [],
   "source": [
    "def plot_hist(hist):\n",
    "    plt.plot(hist.history[\"accuracy\"])\n",
    "    plt.plot(hist.history[\"val_accuracy\"])\n",
    "    plt.title(\"model accuracy\")\n",
    "    plt.ylabel(\"accuracy\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.legend([\"train\", \"validation\"], loc=\"upper left\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-UF4OcdmBp-0"
   },
   "outputs": [],
   "source": [
    "def create_csv(results, results_dir):\n",
    "\n",
    "    csv_fname = 'results_'\n",
    "    csv_fname += datetime.now().strftime('%b%d_%H-%M-%S') + '.csv'\n",
    "\n",
    "    with open(os.path.join(results_dir, csv_fname), 'w') as f:\n",
    "\n",
    "        f.write('Id,Category\\n')\n",
    "\n",
    "        for key, value in results.items():\n",
    "            f.write(key + ',' + str(value) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jf3CL6iGBu4D"
   },
   "outputs": [],
   "source": [
    "def shuffle_validation_weighted(base_dir, split = 0.2, reset = False):\n",
    "    # Create validation_set weighted on number of occurrences in training_set\n",
    "    train_dir = os.path.join(base_dir, 'training')\n",
    "    valid_dir = os.path.join(base_dir, 'validation')\n",
    "\n",
    "    if not reset:\n",
    "        # First identify training and validation dir\n",
    "        if not os.path.exists(valid_dir):\n",
    "            os.makedirs(valid_dir)\n",
    "\n",
    "        # Count elements in each dir in training\n",
    "        class_and_card = {name: len(os.listdir(os.path.join(train_dir, name))) for name in os.listdir(train_dir) if\n",
    "                          os.path.join(train_dir, name)}\n",
    "\n",
    "        print(class_and_card)\n",
    "        # Get images per class wrt total images\n",
    "        class_and_card_validation = {name: int(class_and_card[name] * split) for name in class_and_card}\n",
    "\n",
    "        print(class_and_card_validation)\n",
    "        # Select images to move\n",
    "        for key, item in class_and_card_validation.items():\n",
    "            source_dir = os.path.join(train_dir, key)\n",
    "            images = os.listdir(source_dir)\n",
    "            np.random.shuffle(images)\n",
    "            target_dir = os.path.join(valid_dir, key)\n",
    "            if not os.path.exists(target_dir):\n",
    "                os.makedirs(target_dir)\n",
    "            for i in range(item):\n",
    "                shutil.move(os.path.join(source_dir, images[i]), target_dir)\n",
    "    else:\n",
    "        # Restore initial state\n",
    "        # For each class, move images to train_dir in respective folders\n",
    "        classes = [name for name in os.listdir(valid_dir)]\n",
    "        for class_name in classes:\n",
    "            source_dir = os.path.join(valid_dir, class_name)\n",
    "            images = os.listdir(source_dir)\n",
    "            target_dir = os.path.join(train_dir, class_name)\n",
    "            for img in images:\n",
    "                shutil.move(os.path.join(source_dir, img), target_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ytApNJPbB3iq"
   },
   "source": [
    "# Hyperparameters and Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F_7MQKqaB2kJ"
   },
   "outputs": [],
   "source": [
    "# We executed a scoped GridSearch on the following parameters\n",
    "# Dense Layers -> [1, 2, 3] (tested parameters)\n",
    "# Neurons Number -> [256, 512, 1024]\n",
    "# Starting Filter Number -> [8, 16, 32, 64]\n",
    "# Depth -> range(1, 8)\n",
    "# Image Size -> [256] (same for heigth and width)\n",
    "# Batch Size -> [8, 16, 32]\n",
    "# Valid Percentage -> [0.2]\n",
    "# Starting Learning Rate -> [1e-3, 1e-4]\n",
    "# LR1 values -> // not tested\n",
    "# LR2 values -> // not tested\n",
    "# Below we have the best results\n",
    "\n",
    "img_w, img_h = 256, 256\n",
    "num_classes = 3\n",
    "\n",
    "name = \"basic\"\n",
    "SEED = 4454\n",
    "np.random.seed(SEED)\n",
    "\n",
    "batch_size = 16\n",
    "valid_split_perc = 0.2\n",
    "epochs_fine = 200\n",
    "learning_rate = 1e-4\n",
    "\n",
    "dense_neurons = 512\n",
    "depth = 6\n",
    "start_f = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ESZEKXi5EaFK"
   },
   "outputs": [],
   "source": [
    "cb_early_stopper = EarlyStopping(monitor = 'val_loss', patience = 8)\n",
    "cb_checkpointer = ModelCheckpoint(filepath = name + '_1.hdf5', monitor = 'val_loss', save_best_only = True)\n",
    "cb_plateau = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=4, min_lr=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9GOOlQv9B3ir"
   },
   "source": [
    "# Dataset Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ssLXOsHlBsSQ"
   },
   "outputs": [],
   "source": [
    "cwd = './'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p-VyzhSCBz9u",
    "outputId": "4ea6cc01-3001-4294-870a-6b0b7fba7301"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': 1900, '1': 1897, '2': 1817}\n",
      "{'0': 380, '1': 379, '2': 363}\n"
     ]
    }
   ],
   "source": [
    "shuffle_validation_weighted(cwd, reset=True)\n",
    "shuffle_validation_weighted(cwd, split=valid_split_perc, reset=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bgy1H08FB4Ct",
    "outputId": "9304581b-c478-4daf-f916-e0c1a83ac075"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4492 images belonging to 3 classes.\n",
      "Found 1122 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rotation_range=40,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True,\n",
    "                                   vertical_flip=True,\n",
    "                                   fill_mode=\"nearest\",\n",
    "                                   rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(os.path.join(cwd, 'training'),\n",
    "                                                    target_size=(img_w, img_h),\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    shuffle=True,\n",
    "                                                    class_mode='categorical',\n",
    "                                                    seed = SEED)\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(os.path.join(cwd, 'validation'),\n",
    "                                                target_size=(img_w, img_h),\n",
    "                                                batch_size=batch_size,\n",
    "                                                shuffle=False,\n",
    "                                                class_mode='categorical',\n",
    "                                                seed = SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "26yp4iVOB3is"
   },
   "source": [
    "# Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-IGjpvC8CXdH"
   },
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "\n",
    "# This is a plain model which increases filter number for each depth\n",
    "# A FC at the end decreaes filter number each layer\n",
    "for i in range(depth):\n",
    "  if i == 0:\n",
    "    input_shape = (img_h, img_w, 3)\n",
    "  else:\n",
    "    input_shape = (None, None)\n",
    "\n",
    "  model.add(tf.keras.layers.Conv2D(filters=start_f,\n",
    "                                  kernel_size=(3, 3),\n",
    "                                  strides=(1, 1),\n",
    "                                  padding='same',\n",
    "                                  activation='relu',\n",
    "                                  input_shape=input_shape))\n",
    "  model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2)))\n",
    "  start_f *= 2\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(dense_neurons, activation='relu'))\n",
    "model.add(layers.Dense(dense_neurons//2, activation='relu'))\n",
    "model.add(layers.Dense(dense_neurons//4, activation='relu'))\n",
    "model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=keras.optimizers.Adam(lr=learning_rate),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B9bVrrNBB3it"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "THcKe4uSEaa2"
   },
   "outputs": [],
   "source": [
    "# The result is commented on the document\n",
    "\n",
    "hist = model.fit(train_generator,\n",
    "                 steps_per_epoch=len(train_generator),\n",
    "                 epochs=epochs_fine,\n",
    "                 validation_data=val_generator,\n",
    "                 validation_steps=len(val_generator),\n",
    "                 callbacks=[cb_checkpointer, cb_early_stopper, cb_plateau],\n",
    "                 verbose = 1)\n",
    "\n",
    "plot_hist(hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6e88DEmEB3iu"
   },
   "source": [
    "# Testing and Creating CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZNWd-M1aRq9R"
   },
   "outputs": [],
   "source": [
    "model.load_weights(name + \"_1.hdf5\")\n",
    "        \n",
    "test_dir = os.path.join(cwd, 'test')\n",
    "\n",
    "test_data_gen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_gen = test_data_gen.flow_from_directory(test_dir, target_size=(img_h, img_w),\n",
    "                                             color_mode='rgb',\n",
    "                                             class_mode='categorical',\n",
    "                                             classes = None,\n",
    "                                             batch_size=1,\n",
    "                                             shuffle=False)\n",
    "test_gen.reset()\n",
    "\n",
    "predictions = model.predict(test_gen, verbose=1)\n",
    "\n",
    "results = {}\n",
    "\n",
    "images = test_gen.filenames\n",
    "i = 0\n",
    "\n",
    "for p in predictions:\n",
    "  prediction = np.argmax(p)\n",
    "  import ntpath\n",
    "  image_name = ntpath.basename(images[i])\n",
    "  results[image_name] = str(prediction)\n",
    "  i = i + 1\n",
    "  \n",
    "create_csv(results, cwd)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Top_Basic_HW1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
